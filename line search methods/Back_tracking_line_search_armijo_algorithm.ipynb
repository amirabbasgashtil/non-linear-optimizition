{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJegM8CklrtPKUJ1963VkL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amirabbasgashtil/non-linear-optimizition/blob/main/line%20search%20methods/Back_tracking_line_search_armijo_algorithm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Back-tracking line search algorithm with armijo rule"
      ],
      "metadata": {
        "id": "IHyTOdqHdJ6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "c9SuQGiQm2qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 1. define the function, calculate the gradient and Hessian\n",
        "\n",
        " for example we choose $f(x,y) = x^2 + y^2$"
      ],
      "metadata": {
        "id": "V2Rs5BkSdZas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_plot():\n",
        "  x = np.linspace(-10,10,1000)\n",
        "  y = f(x) # edit this\n",
        "\n",
        "  plt.plot(x,y)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Y6UdUiJ_vFWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return x[0] ** 2 + x[1] ** 2"
      ],
      "metadata": {
        "id": "afN2jfnadWi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_f(x):\n",
        "  x0 = x[0]\n",
        "  x1 = x[1]\n",
        "  return np.array([2 * x0, 2 * x1])"
      ],
      "metadata": {
        "id": "AIOGoAL3lpvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Hessian_f(x):\n",
        "  return np.array([[2,0],[0,2]])"
      ],
      "metadata": {
        "id": "HhPn7XfpmU6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Hessian_inverse(H):\n",
        "  return np.linalg.inv(H)"
      ],
      "metadata": {
        "id": "pg64jHnUoHLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  the $\\phi$ of $\\alpha$ :\n",
        "\n",
        "  $\\phi(\\alpha) = f(x_k + \\alpha_k * p_k)$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "  the L of $\\alpha$ :\n",
        "\n",
        "  $L(\\alpha) = f(x_k) + c \\alpha_k \\nabla f^{T}(x_k)p_k$\n",
        "\n",
        "  which c is a scalar, $0<c<1$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "  armijo rule:\n",
        "\n",
        "  ϕ(α)≤L(α)"
      ],
      "metadata": {
        "id": "4FtC3qBbfvcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_alpha(x,p_k,alpha_k, beta, c):\n",
        "  is_find = False\n",
        "  while is_find is False:\n",
        "    if f(x + alpha_k * p_k) <= f(x) + c * alpha_k * np.dot(gradient_f(x), p_k):\n",
        "      is_find = True\n",
        "    else:\n",
        "      alpha_k = alpha_k * beta\n",
        "  return alpha_k"
      ],
      "metadata": {
        "id": "W_vAYIx3kCP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def newtons_method(f, x0, convergence_thresh=0.12, beta=0.8, c=0.6, max_itrs=10**5):\n",
        "  converged = False\n",
        "  itr_count = 0\n",
        "  x = x0\n",
        "  trajectory=[]\n",
        "  alpha = 1\n",
        "  while converged is False:\n",
        "    p_k = - gradient_f(x) / np.linalg.norm(gradient_f(x))\n",
        "    alpha = find_alpha(x, p_k, alpha, beta, c)\n",
        "    B = Hessian_inverse(Hessian_f(x))\n",
        "\n",
        "    itr_count += 1\n",
        "    trajectory.append(x)\n",
        "    x = x + alpha * B @ p_k\n",
        "\n",
        "    #convergence\n",
        "    if np.linalg.norm(gradient_f(x)) <= convergence_thresh:\n",
        "      converged = True\n",
        "      trajectory.append(x)\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "DRexHOinJ4oO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}